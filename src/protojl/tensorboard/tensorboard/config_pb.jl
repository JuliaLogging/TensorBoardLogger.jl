# Autogenerated using ProtoBuf.jl v1.0.11 on 2023-08-09T10:18:18.633
# original file: proto/tensorboard/tensorboard/config.proto (proto3 syntax)

import ProtoBuf as PB
using ProtoBuf: OneOf
using ProtoBuf.EnumX: @enumx

export var"OptimizerOptions.Level", var"GPUOptions.Experimental.VirtualDevices"
export ThreadPoolOptionProto, var"OptimizerOptions.GlobalJitLevel"
export var"RunMetadata.FunctionGraphs", TensorConnection
export var"ConfigProto.Experimental.MlirBridgeRollout", var"RunOptions.TraceLevel"
export var"RunOptions.Experimental.RunHandlerPoolOptions", SessionMetadata
export var"GPUOptions.Experimental", OptimizerOptions, var"RunOptions.Experimental"
export var"ConfigProto.Experimental", RunMetadata, GPUOptions, GraphOptions, RunOptions
export ConfigProto, CallableOptions

@enumx var"OptimizerOptions.Level" L1=0 L0=-1

struct var"GPUOptions.Experimental.VirtualDevices"
    memory_limit_mb::Vector{Float32}
    priority::Vector{Int32}
    device_ordinal::Vector{Int32}
end
PB.default_values(::Type{var"GPUOptions.Experimental.VirtualDevices"}) = (;memory_limit_mb = Vector{Float32}(), priority = Vector{Int32}(), device_ordinal = Vector{Int32}())
PB.field_numbers(::Type{var"GPUOptions.Experimental.VirtualDevices"}) = (;memory_limit_mb = 1, priority = 2, device_ordinal = 3)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"GPUOptions.Experimental.VirtualDevices"})
    memory_limit_mb = PB.BufferedVector{Float32}()
    priority = PB.BufferedVector{Int32}()
    device_ordinal = PB.BufferedVector{Int32}()
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, wire_type, memory_limit_mb)
        elseif field_number == 2
            PB.decode!(d, wire_type, priority)
        elseif field_number == 3
            PB.decode!(d, wire_type, device_ordinal)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"GPUOptions.Experimental.VirtualDevices"(memory_limit_mb[], priority[], device_ordinal[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"GPUOptions.Experimental.VirtualDevices")
    initpos = position(e.io)
    !isempty(x.memory_limit_mb) && PB.encode(e, 1, x.memory_limit_mb)
    !isempty(x.priority) && PB.encode(e, 2, x.priority)
    !isempty(x.device_ordinal) && PB.encode(e, 3, x.device_ordinal)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"GPUOptions.Experimental.VirtualDevices")
    encoded_size = 0
    !isempty(x.memory_limit_mb) && (encoded_size += PB._encoded_size(x.memory_limit_mb, 1))
    !isempty(x.priority) && (encoded_size += PB._encoded_size(x.priority, 2))
    !isempty(x.device_ordinal) && (encoded_size += PB._encoded_size(x.device_ordinal, 3))
    return encoded_size
end

struct ThreadPoolOptionProto
    num_threads::Int32
    global_name::String
end
PB.default_values(::Type{ThreadPoolOptionProto}) = (;num_threads = zero(Int32), global_name = "")
PB.field_numbers(::Type{ThreadPoolOptionProto}) = (;num_threads = 1, global_name = 2)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:ThreadPoolOptionProto})
    num_threads = zero(Int32)
    global_name = ""
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            num_threads = PB.decode(d, Int32)
        elseif field_number == 2
            global_name = PB.decode(d, String)
        else
            PB.skip(d, wire_type)
        end
    end
    return ThreadPoolOptionProto(num_threads, global_name)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::ThreadPoolOptionProto)
    initpos = position(e.io)
    x.num_threads != zero(Int32) && PB.encode(e, 1, x.num_threads)
    !isempty(x.global_name) && PB.encode(e, 2, x.global_name)
    return position(e.io) - initpos
end
function PB._encoded_size(x::ThreadPoolOptionProto)
    encoded_size = 0
    x.num_threads != zero(Int32) && (encoded_size += PB._encoded_size(x.num_threads, 1))
    !isempty(x.global_name) && (encoded_size += PB._encoded_size(x.global_name, 2))
    return encoded_size
end

@enumx var"OptimizerOptions.GlobalJitLevel" DEFAULT=0 OFF=-1 ON_1=1 ON_2=2

struct var"RunMetadata.FunctionGraphs"
    partition_graphs::Vector{GraphDef}
    pre_optimization_graph::Union{Nothing,GraphDef}
    post_optimization_graph::Union{Nothing,GraphDef}
end
PB.default_values(::Type{var"RunMetadata.FunctionGraphs"}) = (;partition_graphs = Vector{GraphDef}(), pre_optimization_graph = nothing, post_optimization_graph = nothing)
PB.field_numbers(::Type{var"RunMetadata.FunctionGraphs"}) = (;partition_graphs = 1, pre_optimization_graph = 2, post_optimization_graph = 3)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"RunMetadata.FunctionGraphs"})
    partition_graphs = PB.BufferedVector{GraphDef}()
    pre_optimization_graph = Ref{Union{Nothing,GraphDef}}(nothing)
    post_optimization_graph = Ref{Union{Nothing,GraphDef}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, partition_graphs)
        elseif field_number == 2
            PB.decode!(d, pre_optimization_graph)
        elseif field_number == 3
            PB.decode!(d, post_optimization_graph)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"RunMetadata.FunctionGraphs"(partition_graphs[], pre_optimization_graph[], post_optimization_graph[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"RunMetadata.FunctionGraphs")
    initpos = position(e.io)
    !isempty(x.partition_graphs) && PB.encode(e, 1, x.partition_graphs)
    !isnothing(x.pre_optimization_graph) && PB.encode(e, 2, x.pre_optimization_graph)
    !isnothing(x.post_optimization_graph) && PB.encode(e, 3, x.post_optimization_graph)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"RunMetadata.FunctionGraphs")
    encoded_size = 0
    !isempty(x.partition_graphs) && (encoded_size += PB._encoded_size(x.partition_graphs, 1))
    !isnothing(x.pre_optimization_graph) && (encoded_size += PB._encoded_size(x.pre_optimization_graph, 2))
    !isnothing(x.post_optimization_graph) && (encoded_size += PB._encoded_size(x.post_optimization_graph, 3))
    return encoded_size
end

struct TensorConnection
    from_tensor::String
    to_tensor::String
end
PB.default_values(::Type{TensorConnection}) = (;from_tensor = "", to_tensor = "")
PB.field_numbers(::Type{TensorConnection}) = (;from_tensor = 1, to_tensor = 2)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:TensorConnection})
    from_tensor = ""
    to_tensor = ""
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            from_tensor = PB.decode(d, String)
        elseif field_number == 2
            to_tensor = PB.decode(d, String)
        else
            PB.skip(d, wire_type)
        end
    end
    return TensorConnection(from_tensor, to_tensor)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::TensorConnection)
    initpos = position(e.io)
    !isempty(x.from_tensor) && PB.encode(e, 1, x.from_tensor)
    !isempty(x.to_tensor) && PB.encode(e, 2, x.to_tensor)
    return position(e.io) - initpos
end
function PB._encoded_size(x::TensorConnection)
    encoded_size = 0
    !isempty(x.from_tensor) && (encoded_size += PB._encoded_size(x.from_tensor, 1))
    !isempty(x.to_tensor) && (encoded_size += PB._encoded_size(x.to_tensor, 2))
    return encoded_size
end

@enumx var"ConfigProto.Experimental.MlirBridgeRollout" MLIR_BRIDGE_ROLLOUT_UNSPECIFIED=0 MLIR_BRIDGE_ROLLOUT_ENABLED=1 MLIR_BRIDGE_ROLLOUT_DISABLED=2
PB.reserved_fields(::Type{var"ConfigProto.Experimental.MlirBridgeRollout".T}) = (names = ["MLIR_BRIDGE_ROLLOUT_SAFE_MODE_ENABLED", "MLIR_BRIDGE_ROLLOUT_SAFE_MODE_FALLBACK_ENABLED"], numbers = Union{Int,UnitRange{Int}}[3, 4])

@enumx var"RunOptions.TraceLevel" NO_TRACE=0 SOFTWARE_TRACE=1 HARDWARE_TRACE=2 FULL_TRACE=3

struct var"RunOptions.Experimental.RunHandlerPoolOptions"
    priority::Int64
end
PB.default_values(::Type{var"RunOptions.Experimental.RunHandlerPoolOptions"}) = (;priority = zero(Int64))
PB.field_numbers(::Type{var"RunOptions.Experimental.RunHandlerPoolOptions"}) = (;priority = 1)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"RunOptions.Experimental.RunHandlerPoolOptions"})
    priority = zero(Int64)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            priority = PB.decode(d, Int64)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"RunOptions.Experimental.RunHandlerPoolOptions"(priority)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"RunOptions.Experimental.RunHandlerPoolOptions")
    initpos = position(e.io)
    x.priority != zero(Int64) && PB.encode(e, 1, x.priority)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"RunOptions.Experimental.RunHandlerPoolOptions")
    encoded_size = 0
    x.priority != zero(Int64) && (encoded_size += PB._encoded_size(x.priority, 1))
    return encoded_size
end

struct SessionMetadata
    name::String
    version::Int64
end
PB.default_values(::Type{SessionMetadata}) = (;name = "", version = zero(Int64))
PB.field_numbers(::Type{SessionMetadata}) = (;name = 1, version = 2)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:SessionMetadata})
    name = ""
    version = zero(Int64)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            name = PB.decode(d, String)
        elseif field_number == 2
            version = PB.decode(d, Int64)
        else
            PB.skip(d, wire_type)
        end
    end
    return SessionMetadata(name, version)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::SessionMetadata)
    initpos = position(e.io)
    !isempty(x.name) && PB.encode(e, 1, x.name)
    x.version != zero(Int64) && PB.encode(e, 2, x.version)
    return position(e.io) - initpos
end
function PB._encoded_size(x::SessionMetadata)
    encoded_size = 0
    !isempty(x.name) && (encoded_size += PB._encoded_size(x.name, 1))
    x.version != zero(Int64) && (encoded_size += PB._encoded_size(x.version, 2))
    return encoded_size
end

struct var"GPUOptions.Experimental"
    virtual_devices::Vector{var"GPUOptions.Experimental.VirtualDevices"}
    use_unified_memory::Bool
    num_dev_to_dev_copy_streams::Int32
    collective_ring_order::String
    timestamped_allocator::Bool
    kernel_tracker_max_interval::Int32
    kernel_tracker_max_bytes::Int32
    kernel_tracker_max_pending::Int32
    internal_fragmentation_fraction::Float64
    use_cuda_malloc_async::Bool
    disallow_retry_on_allocation_failure::Bool
    gpu_host_mem_limit_in_mb::Float32
    gpu_host_mem_disallow_growth::Bool
end
PB.default_values(::Type{var"GPUOptions.Experimental"}) = (;virtual_devices = Vector{var"GPUOptions.Experimental.VirtualDevices"}(), use_unified_memory = false, num_dev_to_dev_copy_streams = zero(Int32), collective_ring_order = "", timestamped_allocator = false, kernel_tracker_max_interval = zero(Int32), kernel_tracker_max_bytes = zero(Int32), kernel_tracker_max_pending = zero(Int32), internal_fragmentation_fraction = zero(Float64), use_cuda_malloc_async = false, disallow_retry_on_allocation_failure = false, gpu_host_mem_limit_in_mb = zero(Float32), gpu_host_mem_disallow_growth = false)
PB.field_numbers(::Type{var"GPUOptions.Experimental"}) = (;virtual_devices = 1, use_unified_memory = 2, num_dev_to_dev_copy_streams = 3, collective_ring_order = 4, timestamped_allocator = 5, kernel_tracker_max_interval = 7, kernel_tracker_max_bytes = 8, kernel_tracker_max_pending = 9, internal_fragmentation_fraction = 10, use_cuda_malloc_async = 11, disallow_retry_on_allocation_failure = 12, gpu_host_mem_limit_in_mb = 13, gpu_host_mem_disallow_growth = 14)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"GPUOptions.Experimental"})
    virtual_devices = PB.BufferedVector{var"GPUOptions.Experimental.VirtualDevices"}()
    use_unified_memory = false
    num_dev_to_dev_copy_streams = zero(Int32)
    collective_ring_order = ""
    timestamped_allocator = false
    kernel_tracker_max_interval = zero(Int32)
    kernel_tracker_max_bytes = zero(Int32)
    kernel_tracker_max_pending = zero(Int32)
    internal_fragmentation_fraction = zero(Float64)
    use_cuda_malloc_async = false
    disallow_retry_on_allocation_failure = false
    gpu_host_mem_limit_in_mb = zero(Float32)
    gpu_host_mem_disallow_growth = false
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, virtual_devices)
        elseif field_number == 2
            use_unified_memory = PB.decode(d, Bool)
        elseif field_number == 3
            num_dev_to_dev_copy_streams = PB.decode(d, Int32)
        elseif field_number == 4
            collective_ring_order = PB.decode(d, String)
        elseif field_number == 5
            timestamped_allocator = PB.decode(d, Bool)
        elseif field_number == 7
            kernel_tracker_max_interval = PB.decode(d, Int32)
        elseif field_number == 8
            kernel_tracker_max_bytes = PB.decode(d, Int32)
        elseif field_number == 9
            kernel_tracker_max_pending = PB.decode(d, Int32)
        elseif field_number == 10
            internal_fragmentation_fraction = PB.decode(d, Float64)
        elseif field_number == 11
            use_cuda_malloc_async = PB.decode(d, Bool)
        elseif field_number == 12
            disallow_retry_on_allocation_failure = PB.decode(d, Bool)
        elseif field_number == 13
            gpu_host_mem_limit_in_mb = PB.decode(d, Float32)
        elseif field_number == 14
            gpu_host_mem_disallow_growth = PB.decode(d, Bool)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"GPUOptions.Experimental"(virtual_devices[], use_unified_memory, num_dev_to_dev_copy_streams, collective_ring_order, timestamped_allocator, kernel_tracker_max_interval, kernel_tracker_max_bytes, kernel_tracker_max_pending, internal_fragmentation_fraction, use_cuda_malloc_async, disallow_retry_on_allocation_failure, gpu_host_mem_limit_in_mb, gpu_host_mem_disallow_growth)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"GPUOptions.Experimental")
    initpos = position(e.io)
    !isempty(x.virtual_devices) && PB.encode(e, 1, x.virtual_devices)
    x.use_unified_memory != false && PB.encode(e, 2, x.use_unified_memory)
    x.num_dev_to_dev_copy_streams != zero(Int32) && PB.encode(e, 3, x.num_dev_to_dev_copy_streams)
    !isempty(x.collective_ring_order) && PB.encode(e, 4, x.collective_ring_order)
    x.timestamped_allocator != false && PB.encode(e, 5, x.timestamped_allocator)
    x.kernel_tracker_max_interval != zero(Int32) && PB.encode(e, 7, x.kernel_tracker_max_interval)
    x.kernel_tracker_max_bytes != zero(Int32) && PB.encode(e, 8, x.kernel_tracker_max_bytes)
    x.kernel_tracker_max_pending != zero(Int32) && PB.encode(e, 9, x.kernel_tracker_max_pending)
    x.internal_fragmentation_fraction != zero(Float64) && PB.encode(e, 10, x.internal_fragmentation_fraction)
    x.use_cuda_malloc_async != false && PB.encode(e, 11, x.use_cuda_malloc_async)
    x.disallow_retry_on_allocation_failure != false && PB.encode(e, 12, x.disallow_retry_on_allocation_failure)
    x.gpu_host_mem_limit_in_mb != zero(Float32) && PB.encode(e, 13, x.gpu_host_mem_limit_in_mb)
    x.gpu_host_mem_disallow_growth != false && PB.encode(e, 14, x.gpu_host_mem_disallow_growth)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"GPUOptions.Experimental")
    encoded_size = 0
    !isempty(x.virtual_devices) && (encoded_size += PB._encoded_size(x.virtual_devices, 1))
    x.use_unified_memory != false && (encoded_size += PB._encoded_size(x.use_unified_memory, 2))
    x.num_dev_to_dev_copy_streams != zero(Int32) && (encoded_size += PB._encoded_size(x.num_dev_to_dev_copy_streams, 3))
    !isempty(x.collective_ring_order) && (encoded_size += PB._encoded_size(x.collective_ring_order, 4))
    x.timestamped_allocator != false && (encoded_size += PB._encoded_size(x.timestamped_allocator, 5))
    x.kernel_tracker_max_interval != zero(Int32) && (encoded_size += PB._encoded_size(x.kernel_tracker_max_interval, 7))
    x.kernel_tracker_max_bytes != zero(Int32) && (encoded_size += PB._encoded_size(x.kernel_tracker_max_bytes, 8))
    x.kernel_tracker_max_pending != zero(Int32) && (encoded_size += PB._encoded_size(x.kernel_tracker_max_pending, 9))
    x.internal_fragmentation_fraction != zero(Float64) && (encoded_size += PB._encoded_size(x.internal_fragmentation_fraction, 10))
    x.use_cuda_malloc_async != false && (encoded_size += PB._encoded_size(x.use_cuda_malloc_async, 11))
    x.disallow_retry_on_allocation_failure != false && (encoded_size += PB._encoded_size(x.disallow_retry_on_allocation_failure, 12))
    x.gpu_host_mem_limit_in_mb != zero(Float32) && (encoded_size += PB._encoded_size(x.gpu_host_mem_limit_in_mb, 13))
    x.gpu_host_mem_disallow_growth != false && (encoded_size += PB._encoded_size(x.gpu_host_mem_disallow_growth, 14))
    return encoded_size
end

struct OptimizerOptions
    do_common_subexpression_elimination::Bool
    do_constant_folding::Bool
    max_folded_constant_in_bytes::Int64
    do_function_inlining::Bool
    opt_level::var"OptimizerOptions.Level".T
    global_jit_level::var"OptimizerOptions.GlobalJitLevel".T
    cpu_global_jit::Bool
end
PB.default_values(::Type{OptimizerOptions}) = (;do_common_subexpression_elimination = false, do_constant_folding = false, max_folded_constant_in_bytes = zero(Int64), do_function_inlining = false, opt_level = var"OptimizerOptions.Level".L1, global_jit_level = var"OptimizerOptions.GlobalJitLevel".DEFAULT, cpu_global_jit = false)
PB.field_numbers(::Type{OptimizerOptions}) = (;do_common_subexpression_elimination = 1, do_constant_folding = 2, max_folded_constant_in_bytes = 6, do_function_inlining = 4, opt_level = 3, global_jit_level = 5, cpu_global_jit = 7)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:OptimizerOptions})
    do_common_subexpression_elimination = false
    do_constant_folding = false
    max_folded_constant_in_bytes = zero(Int64)
    do_function_inlining = false
    opt_level = var"OptimizerOptions.Level".L1
    global_jit_level = var"OptimizerOptions.GlobalJitLevel".DEFAULT
    cpu_global_jit = false
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            do_common_subexpression_elimination = PB.decode(d, Bool)
        elseif field_number == 2
            do_constant_folding = PB.decode(d, Bool)
        elseif field_number == 6
            max_folded_constant_in_bytes = PB.decode(d, Int64)
        elseif field_number == 4
            do_function_inlining = PB.decode(d, Bool)
        elseif field_number == 3
            opt_level = PB.decode(d, var"OptimizerOptions.Level".T)
        elseif field_number == 5
            global_jit_level = PB.decode(d, var"OptimizerOptions.GlobalJitLevel".T)
        elseif field_number == 7
            cpu_global_jit = PB.decode(d, Bool)
        else
            PB.skip(d, wire_type)
        end
    end
    return OptimizerOptions(do_common_subexpression_elimination, do_constant_folding, max_folded_constant_in_bytes, do_function_inlining, opt_level, global_jit_level, cpu_global_jit)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::OptimizerOptions)
    initpos = position(e.io)
    x.do_common_subexpression_elimination != false && PB.encode(e, 1, x.do_common_subexpression_elimination)
    x.do_constant_folding != false && PB.encode(e, 2, x.do_constant_folding)
    x.max_folded_constant_in_bytes != zero(Int64) && PB.encode(e, 6, x.max_folded_constant_in_bytes)
    x.do_function_inlining != false && PB.encode(e, 4, x.do_function_inlining)
    x.opt_level != var"OptimizerOptions.Level".L1 && PB.encode(e, 3, x.opt_level)
    x.global_jit_level != var"OptimizerOptions.GlobalJitLevel".DEFAULT && PB.encode(e, 5, x.global_jit_level)
    x.cpu_global_jit != false && PB.encode(e, 7, x.cpu_global_jit)
    return position(e.io) - initpos
end
function PB._encoded_size(x::OptimizerOptions)
    encoded_size = 0
    x.do_common_subexpression_elimination != false && (encoded_size += PB._encoded_size(x.do_common_subexpression_elimination, 1))
    x.do_constant_folding != false && (encoded_size += PB._encoded_size(x.do_constant_folding, 2))
    x.max_folded_constant_in_bytes != zero(Int64) && (encoded_size += PB._encoded_size(x.max_folded_constant_in_bytes, 6))
    x.do_function_inlining != false && (encoded_size += PB._encoded_size(x.do_function_inlining, 4))
    x.opt_level != var"OptimizerOptions.Level".L1 && (encoded_size += PB._encoded_size(x.opt_level, 3))
    x.global_jit_level != var"OptimizerOptions.GlobalJitLevel".DEFAULT && (encoded_size += PB._encoded_size(x.global_jit_level, 5))
    x.cpu_global_jit != false && (encoded_size += PB._encoded_size(x.cpu_global_jit, 7))
    return encoded_size
end

struct var"RunOptions.Experimental"
    collective_graph_key::Int64
    use_run_handler_pool::Bool
    run_handler_pool_options::Union{Nothing,var"RunOptions.Experimental.RunHandlerPoolOptions"}
end
PB.default_values(::Type{var"RunOptions.Experimental"}) = (;collective_graph_key = zero(Int64), use_run_handler_pool = false, run_handler_pool_options = nothing)
PB.field_numbers(::Type{var"RunOptions.Experimental"}) = (;collective_graph_key = 1, use_run_handler_pool = 2, run_handler_pool_options = 3)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"RunOptions.Experimental"})
    collective_graph_key = zero(Int64)
    use_run_handler_pool = false
    run_handler_pool_options = Ref{Union{Nothing,var"RunOptions.Experimental.RunHandlerPoolOptions"}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            collective_graph_key = PB.decode(d, Int64)
        elseif field_number == 2
            use_run_handler_pool = PB.decode(d, Bool)
        elseif field_number == 3
            PB.decode!(d, run_handler_pool_options)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"RunOptions.Experimental"(collective_graph_key, use_run_handler_pool, run_handler_pool_options[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"RunOptions.Experimental")
    initpos = position(e.io)
    x.collective_graph_key != zero(Int64) && PB.encode(e, 1, x.collective_graph_key)
    x.use_run_handler_pool != false && PB.encode(e, 2, x.use_run_handler_pool)
    !isnothing(x.run_handler_pool_options) && PB.encode(e, 3, x.run_handler_pool_options)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"RunOptions.Experimental")
    encoded_size = 0
    x.collective_graph_key != zero(Int64) && (encoded_size += PB._encoded_size(x.collective_graph_key, 1))
    x.use_run_handler_pool != false && (encoded_size += PB._encoded_size(x.use_run_handler_pool, 2))
    !isnothing(x.run_handler_pool_options) && (encoded_size += PB._encoded_size(x.run_handler_pool_options, 3))
    return encoded_size
end

struct var"ConfigProto.Experimental"
    collective_group_leader::String
    executor_type::String
    recv_buf_max_chunk::Int32
    use_numa_affinity::Bool
    collective_deterministic_sequential_execution::Bool
    collective_nccl::Bool
    share_session_state_in_clusterspec_propagation::Bool
    disable_thread_spinning::Bool
    share_cluster_devices_in_session::Bool
    session_metadata::Union{Nothing,SessionMetadata}
    optimize_for_static_graph::Bool
    enable_mlir_bridge::Bool
    mlir_bridge_rollout::var"ConfigProto.Experimental.MlirBridgeRollout".T
    enable_mlir_graph_optimization::Bool
    disable_output_partition_graphs::Bool
    xla_fusion_autotuner_thresh::Int64
    use_tfrt::Bool
    disable_functional_ops_lowering::Bool
    xla_prefer_single_graph_cluster::Bool
    coordination_config::Union{Nothing,CoordinationServiceConfig}
    disable_optimize_for_static_graph::Bool
end
PB.reserved_fields(::Type{var"ConfigProto.Experimental"}) = (names = String[], numbers = Union{Int,UnitRange{Int}}[2, 19, 20, 25])
PB.default_values(::Type{var"ConfigProto.Experimental"}) = (;collective_group_leader = "", executor_type = "", recv_buf_max_chunk = zero(Int32), use_numa_affinity = false, collective_deterministic_sequential_execution = false, collective_nccl = false, share_session_state_in_clusterspec_propagation = false, disable_thread_spinning = false, share_cluster_devices_in_session = false, session_metadata = nothing, optimize_for_static_graph = false, enable_mlir_bridge = false, mlir_bridge_rollout = var"ConfigProto.Experimental.MlirBridgeRollout".MLIR_BRIDGE_ROLLOUT_UNSPECIFIED, enable_mlir_graph_optimization = false, disable_output_partition_graphs = false, xla_fusion_autotuner_thresh = zero(Int64), use_tfrt = false, disable_functional_ops_lowering = false, xla_prefer_single_graph_cluster = false, coordination_config = nothing, disable_optimize_for_static_graph = false)
PB.field_numbers(::Type{var"ConfigProto.Experimental"}) = (;collective_group_leader = 1, executor_type = 3, recv_buf_max_chunk = 4, use_numa_affinity = 5, collective_deterministic_sequential_execution = 6, collective_nccl = 7, share_session_state_in_clusterspec_propagation = 8, disable_thread_spinning = 9, share_cluster_devices_in_session = 10, session_metadata = 11, optimize_for_static_graph = 12, enable_mlir_bridge = 13, mlir_bridge_rollout = 17, enable_mlir_graph_optimization = 16, disable_output_partition_graphs = 14, xla_fusion_autotuner_thresh = 15, use_tfrt = 18, disable_functional_ops_lowering = 21, xla_prefer_single_graph_cluster = 22, coordination_config = 23, disable_optimize_for_static_graph = 24)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:var"ConfigProto.Experimental"})
    collective_group_leader = ""
    executor_type = ""
    recv_buf_max_chunk = zero(Int32)
    use_numa_affinity = false
    collective_deterministic_sequential_execution = false
    collective_nccl = false
    share_session_state_in_clusterspec_propagation = false
    disable_thread_spinning = false
    share_cluster_devices_in_session = false
    session_metadata = Ref{Union{Nothing,SessionMetadata}}(nothing)
    optimize_for_static_graph = false
    enable_mlir_bridge = false
    mlir_bridge_rollout = var"ConfigProto.Experimental.MlirBridgeRollout".MLIR_BRIDGE_ROLLOUT_UNSPECIFIED
    enable_mlir_graph_optimization = false
    disable_output_partition_graphs = false
    xla_fusion_autotuner_thresh = zero(Int64)
    use_tfrt = false
    disable_functional_ops_lowering = false
    xla_prefer_single_graph_cluster = false
    coordination_config = Ref{Union{Nothing,CoordinationServiceConfig}}(nothing)
    disable_optimize_for_static_graph = false
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            collective_group_leader = PB.decode(d, String)
        elseif field_number == 3
            executor_type = PB.decode(d, String)
        elseif field_number == 4
            recv_buf_max_chunk = PB.decode(d, Int32)
        elseif field_number == 5
            use_numa_affinity = PB.decode(d, Bool)
        elseif field_number == 6
            collective_deterministic_sequential_execution = PB.decode(d, Bool)
        elseif field_number == 7
            collective_nccl = PB.decode(d, Bool)
        elseif field_number == 8
            share_session_state_in_clusterspec_propagation = PB.decode(d, Bool)
        elseif field_number == 9
            disable_thread_spinning = PB.decode(d, Bool)
        elseif field_number == 10
            share_cluster_devices_in_session = PB.decode(d, Bool)
        elseif field_number == 11
            PB.decode!(d, session_metadata)
        elseif field_number == 12
            optimize_for_static_graph = PB.decode(d, Bool)
        elseif field_number == 13
            enable_mlir_bridge = PB.decode(d, Bool)
        elseif field_number == 17
            mlir_bridge_rollout = PB.decode(d, var"ConfigProto.Experimental.MlirBridgeRollout".T)
        elseif field_number == 16
            enable_mlir_graph_optimization = PB.decode(d, Bool)
        elseif field_number == 14
            disable_output_partition_graphs = PB.decode(d, Bool)
        elseif field_number == 15
            xla_fusion_autotuner_thresh = PB.decode(d, Int64)
        elseif field_number == 18
            use_tfrt = PB.decode(d, Bool)
        elseif field_number == 21
            disable_functional_ops_lowering = PB.decode(d, Bool)
        elseif field_number == 22
            xla_prefer_single_graph_cluster = PB.decode(d, Bool)
        elseif field_number == 23
            PB.decode!(d, coordination_config)
        elseif field_number == 24
            disable_optimize_for_static_graph = PB.decode(d, Bool)
        else
            PB.skip(d, wire_type)
        end
    end
    return var"ConfigProto.Experimental"(collective_group_leader, executor_type, recv_buf_max_chunk, use_numa_affinity, collective_deterministic_sequential_execution, collective_nccl, share_session_state_in_clusterspec_propagation, disable_thread_spinning, share_cluster_devices_in_session, session_metadata[], optimize_for_static_graph, enable_mlir_bridge, mlir_bridge_rollout, enable_mlir_graph_optimization, disable_output_partition_graphs, xla_fusion_autotuner_thresh, use_tfrt, disable_functional_ops_lowering, xla_prefer_single_graph_cluster, coordination_config[], disable_optimize_for_static_graph)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::var"ConfigProto.Experimental")
    initpos = position(e.io)
    !isempty(x.collective_group_leader) && PB.encode(e, 1, x.collective_group_leader)
    !isempty(x.executor_type) && PB.encode(e, 3, x.executor_type)
    x.recv_buf_max_chunk != zero(Int32) && PB.encode(e, 4, x.recv_buf_max_chunk)
    x.use_numa_affinity != false && PB.encode(e, 5, x.use_numa_affinity)
    x.collective_deterministic_sequential_execution != false && PB.encode(e, 6, x.collective_deterministic_sequential_execution)
    x.collective_nccl != false && PB.encode(e, 7, x.collective_nccl)
    x.share_session_state_in_clusterspec_propagation != false && PB.encode(e, 8, x.share_session_state_in_clusterspec_propagation)
    x.disable_thread_spinning != false && PB.encode(e, 9, x.disable_thread_spinning)
    x.share_cluster_devices_in_session != false && PB.encode(e, 10, x.share_cluster_devices_in_session)
    !isnothing(x.session_metadata) && PB.encode(e, 11, x.session_metadata)
    x.optimize_for_static_graph != false && PB.encode(e, 12, x.optimize_for_static_graph)
    x.enable_mlir_bridge != false && PB.encode(e, 13, x.enable_mlir_bridge)
    x.mlir_bridge_rollout != var"ConfigProto.Experimental.MlirBridgeRollout".MLIR_BRIDGE_ROLLOUT_UNSPECIFIED && PB.encode(e, 17, x.mlir_bridge_rollout)
    x.enable_mlir_graph_optimization != false && PB.encode(e, 16, x.enable_mlir_graph_optimization)
    x.disable_output_partition_graphs != false && PB.encode(e, 14, x.disable_output_partition_graphs)
    x.xla_fusion_autotuner_thresh != zero(Int64) && PB.encode(e, 15, x.xla_fusion_autotuner_thresh)
    x.use_tfrt != false && PB.encode(e, 18, x.use_tfrt)
    x.disable_functional_ops_lowering != false && PB.encode(e, 21, x.disable_functional_ops_lowering)
    x.xla_prefer_single_graph_cluster != false && PB.encode(e, 22, x.xla_prefer_single_graph_cluster)
    !isnothing(x.coordination_config) && PB.encode(e, 23, x.coordination_config)
    x.disable_optimize_for_static_graph != false && PB.encode(e, 24, x.disable_optimize_for_static_graph)
    return position(e.io) - initpos
end
function PB._encoded_size(x::var"ConfigProto.Experimental")
    encoded_size = 0
    !isempty(x.collective_group_leader) && (encoded_size += PB._encoded_size(x.collective_group_leader, 1))
    !isempty(x.executor_type) && (encoded_size += PB._encoded_size(x.executor_type, 3))
    x.recv_buf_max_chunk != zero(Int32) && (encoded_size += PB._encoded_size(x.recv_buf_max_chunk, 4))
    x.use_numa_affinity != false && (encoded_size += PB._encoded_size(x.use_numa_affinity, 5))
    x.collective_deterministic_sequential_execution != false && (encoded_size += PB._encoded_size(x.collective_deterministic_sequential_execution, 6))
    x.collective_nccl != false && (encoded_size += PB._encoded_size(x.collective_nccl, 7))
    x.share_session_state_in_clusterspec_propagation != false && (encoded_size += PB._encoded_size(x.share_session_state_in_clusterspec_propagation, 8))
    x.disable_thread_spinning != false && (encoded_size += PB._encoded_size(x.disable_thread_spinning, 9))
    x.share_cluster_devices_in_session != false && (encoded_size += PB._encoded_size(x.share_cluster_devices_in_session, 10))
    !isnothing(x.session_metadata) && (encoded_size += PB._encoded_size(x.session_metadata, 11))
    x.optimize_for_static_graph != false && (encoded_size += PB._encoded_size(x.optimize_for_static_graph, 12))
    x.enable_mlir_bridge != false && (encoded_size += PB._encoded_size(x.enable_mlir_bridge, 13))
    x.mlir_bridge_rollout != var"ConfigProto.Experimental.MlirBridgeRollout".MLIR_BRIDGE_ROLLOUT_UNSPECIFIED && (encoded_size += PB._encoded_size(x.mlir_bridge_rollout, 17))
    x.enable_mlir_graph_optimization != false && (encoded_size += PB._encoded_size(x.enable_mlir_graph_optimization, 16))
    x.disable_output_partition_graphs != false && (encoded_size += PB._encoded_size(x.disable_output_partition_graphs, 14))
    x.xla_fusion_autotuner_thresh != zero(Int64) && (encoded_size += PB._encoded_size(x.xla_fusion_autotuner_thresh, 15))
    x.use_tfrt != false && (encoded_size += PB._encoded_size(x.use_tfrt, 18))
    x.disable_functional_ops_lowering != false && (encoded_size += PB._encoded_size(x.disable_functional_ops_lowering, 21))
    x.xla_prefer_single_graph_cluster != false && (encoded_size += PB._encoded_size(x.xla_prefer_single_graph_cluster, 22))
    !isnothing(x.coordination_config) && (encoded_size += PB._encoded_size(x.coordination_config, 23))
    x.disable_optimize_for_static_graph != false && (encoded_size += PB._encoded_size(x.disable_optimize_for_static_graph, 24))
    return encoded_size
end

struct RunMetadata
    step_stats::Union{Nothing,StepStats}
    cost_graph::Union{Nothing,CostGraphDef}
    partition_graphs::Vector{GraphDef}
    function_graphs::Vector{var"RunMetadata.FunctionGraphs"}
    session_metadata::Union{Nothing,SessionMetadata}
end
PB.default_values(::Type{RunMetadata}) = (;step_stats = nothing, cost_graph = nothing, partition_graphs = Vector{GraphDef}(), function_graphs = Vector{var"RunMetadata.FunctionGraphs"}(), session_metadata = nothing)
PB.field_numbers(::Type{RunMetadata}) = (;step_stats = 1, cost_graph = 2, partition_graphs = 3, function_graphs = 4, session_metadata = 5)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:RunMetadata})
    step_stats = Ref{Union{Nothing,StepStats}}(nothing)
    cost_graph = Ref{Union{Nothing,CostGraphDef}}(nothing)
    partition_graphs = PB.BufferedVector{GraphDef}()
    function_graphs = PB.BufferedVector{var"RunMetadata.FunctionGraphs"}()
    session_metadata = Ref{Union{Nothing,SessionMetadata}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, step_stats)
        elseif field_number == 2
            PB.decode!(d, cost_graph)
        elseif field_number == 3
            PB.decode!(d, partition_graphs)
        elseif field_number == 4
            PB.decode!(d, function_graphs)
        elseif field_number == 5
            PB.decode!(d, session_metadata)
        else
            PB.skip(d, wire_type)
        end
    end
    return RunMetadata(step_stats[], cost_graph[], partition_graphs[], function_graphs[], session_metadata[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::RunMetadata)
    initpos = position(e.io)
    !isnothing(x.step_stats) && PB.encode(e, 1, x.step_stats)
    !isnothing(x.cost_graph) && PB.encode(e, 2, x.cost_graph)
    !isempty(x.partition_graphs) && PB.encode(e, 3, x.partition_graphs)
    !isempty(x.function_graphs) && PB.encode(e, 4, x.function_graphs)
    !isnothing(x.session_metadata) && PB.encode(e, 5, x.session_metadata)
    return position(e.io) - initpos
end
function PB._encoded_size(x::RunMetadata)
    encoded_size = 0
    !isnothing(x.step_stats) && (encoded_size += PB._encoded_size(x.step_stats, 1))
    !isnothing(x.cost_graph) && (encoded_size += PB._encoded_size(x.cost_graph, 2))
    !isempty(x.partition_graphs) && (encoded_size += PB._encoded_size(x.partition_graphs, 3))
    !isempty(x.function_graphs) && (encoded_size += PB._encoded_size(x.function_graphs, 4))
    !isnothing(x.session_metadata) && (encoded_size += PB._encoded_size(x.session_metadata, 5))
    return encoded_size
end

struct GPUOptions
    per_process_gpu_memory_fraction::Float64
    allow_growth::Bool
    allocator_type::String
    deferred_deletion_bytes::Int64
    visible_device_list::String
    polling_active_delay_usecs::Int32
    polling_inactive_delay_msecs::Int32
    force_gpu_compatible::Bool
    experimental::Union{Nothing,var"GPUOptions.Experimental"}
end
PB.default_values(::Type{GPUOptions}) = (;per_process_gpu_memory_fraction = zero(Float64), allow_growth = false, allocator_type = "", deferred_deletion_bytes = zero(Int64), visible_device_list = "", polling_active_delay_usecs = zero(Int32), polling_inactive_delay_msecs = zero(Int32), force_gpu_compatible = false, experimental = nothing)
PB.field_numbers(::Type{GPUOptions}) = (;per_process_gpu_memory_fraction = 1, allow_growth = 4, allocator_type = 2, deferred_deletion_bytes = 3, visible_device_list = 5, polling_active_delay_usecs = 6, polling_inactive_delay_msecs = 7, force_gpu_compatible = 8, experimental = 9)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:GPUOptions})
    per_process_gpu_memory_fraction = zero(Float64)
    allow_growth = false
    allocator_type = ""
    deferred_deletion_bytes = zero(Int64)
    visible_device_list = ""
    polling_active_delay_usecs = zero(Int32)
    polling_inactive_delay_msecs = zero(Int32)
    force_gpu_compatible = false
    experimental = Ref{Union{Nothing,var"GPUOptions.Experimental"}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            per_process_gpu_memory_fraction = PB.decode(d, Float64)
        elseif field_number == 4
            allow_growth = PB.decode(d, Bool)
        elseif field_number == 2
            allocator_type = PB.decode(d, String)
        elseif field_number == 3
            deferred_deletion_bytes = PB.decode(d, Int64)
        elseif field_number == 5
            visible_device_list = PB.decode(d, String)
        elseif field_number == 6
            polling_active_delay_usecs = PB.decode(d, Int32)
        elseif field_number == 7
            polling_inactive_delay_msecs = PB.decode(d, Int32)
        elseif field_number == 8
            force_gpu_compatible = PB.decode(d, Bool)
        elseif field_number == 9
            PB.decode!(d, experimental)
        else
            PB.skip(d, wire_type)
        end
    end
    return GPUOptions(per_process_gpu_memory_fraction, allow_growth, allocator_type, deferred_deletion_bytes, visible_device_list, polling_active_delay_usecs, polling_inactive_delay_msecs, force_gpu_compatible, experimental[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::GPUOptions)
    initpos = position(e.io)
    x.per_process_gpu_memory_fraction != zero(Float64) && PB.encode(e, 1, x.per_process_gpu_memory_fraction)
    x.allow_growth != false && PB.encode(e, 4, x.allow_growth)
    !isempty(x.allocator_type) && PB.encode(e, 2, x.allocator_type)
    x.deferred_deletion_bytes != zero(Int64) && PB.encode(e, 3, x.deferred_deletion_bytes)
    !isempty(x.visible_device_list) && PB.encode(e, 5, x.visible_device_list)
    x.polling_active_delay_usecs != zero(Int32) && PB.encode(e, 6, x.polling_active_delay_usecs)
    x.polling_inactive_delay_msecs != zero(Int32) && PB.encode(e, 7, x.polling_inactive_delay_msecs)
    x.force_gpu_compatible != false && PB.encode(e, 8, x.force_gpu_compatible)
    !isnothing(x.experimental) && PB.encode(e, 9, x.experimental)
    return position(e.io) - initpos
end
function PB._encoded_size(x::GPUOptions)
    encoded_size = 0
    x.per_process_gpu_memory_fraction != zero(Float64) && (encoded_size += PB._encoded_size(x.per_process_gpu_memory_fraction, 1))
    x.allow_growth != false && (encoded_size += PB._encoded_size(x.allow_growth, 4))
    !isempty(x.allocator_type) && (encoded_size += PB._encoded_size(x.allocator_type, 2))
    x.deferred_deletion_bytes != zero(Int64) && (encoded_size += PB._encoded_size(x.deferred_deletion_bytes, 3))
    !isempty(x.visible_device_list) && (encoded_size += PB._encoded_size(x.visible_device_list, 5))
    x.polling_active_delay_usecs != zero(Int32) && (encoded_size += PB._encoded_size(x.polling_active_delay_usecs, 6))
    x.polling_inactive_delay_msecs != zero(Int32) && (encoded_size += PB._encoded_size(x.polling_inactive_delay_msecs, 7))
    x.force_gpu_compatible != false && (encoded_size += PB._encoded_size(x.force_gpu_compatible, 8))
    !isnothing(x.experimental) && (encoded_size += PB._encoded_size(x.experimental, 9))
    return encoded_size
end

struct GraphOptions
    enable_recv_scheduling::Bool
    optimizer_options::Union{Nothing,OptimizerOptions}
    build_cost_model::Int64
    build_cost_model_after::Int64
    infer_shapes::Bool
    place_pruned_graph::Bool
    enable_bfloat16_sendrecv::Bool
    timeline_step::Int32
    rewrite_options::Union{Nothing,RewriterConfig}
end
PB.reserved_fields(::Type{GraphOptions}) = (names = ["skip_common_subexpression_elimination"], numbers = Union{Int,UnitRange{Int}}[1])
PB.default_values(::Type{GraphOptions}) = (;enable_recv_scheduling = false, optimizer_options = nothing, build_cost_model = zero(Int64), build_cost_model_after = zero(Int64), infer_shapes = false, place_pruned_graph = false, enable_bfloat16_sendrecv = false, timeline_step = zero(Int32), rewrite_options = nothing)
PB.field_numbers(::Type{GraphOptions}) = (;enable_recv_scheduling = 2, optimizer_options = 3, build_cost_model = 4, build_cost_model_after = 9, infer_shapes = 5, place_pruned_graph = 6, enable_bfloat16_sendrecv = 7, timeline_step = 8, rewrite_options = 10)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:GraphOptions})
    enable_recv_scheduling = false
    optimizer_options = Ref{Union{Nothing,OptimizerOptions}}(nothing)
    build_cost_model = zero(Int64)
    build_cost_model_after = zero(Int64)
    infer_shapes = false
    place_pruned_graph = false
    enable_bfloat16_sendrecv = false
    timeline_step = zero(Int32)
    rewrite_options = Ref{Union{Nothing,RewriterConfig}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 2
            enable_recv_scheduling = PB.decode(d, Bool)
        elseif field_number == 3
            PB.decode!(d, optimizer_options)
        elseif field_number == 4
            build_cost_model = PB.decode(d, Int64)
        elseif field_number == 9
            build_cost_model_after = PB.decode(d, Int64)
        elseif field_number == 5
            infer_shapes = PB.decode(d, Bool)
        elseif field_number == 6
            place_pruned_graph = PB.decode(d, Bool)
        elseif field_number == 7
            enable_bfloat16_sendrecv = PB.decode(d, Bool)
        elseif field_number == 8
            timeline_step = PB.decode(d, Int32)
        elseif field_number == 10
            PB.decode!(d, rewrite_options)
        else
            PB.skip(d, wire_type)
        end
    end
    return GraphOptions(enable_recv_scheduling, optimizer_options[], build_cost_model, build_cost_model_after, infer_shapes, place_pruned_graph, enable_bfloat16_sendrecv, timeline_step, rewrite_options[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::GraphOptions)
    initpos = position(e.io)
    x.enable_recv_scheduling != false && PB.encode(e, 2, x.enable_recv_scheduling)
    !isnothing(x.optimizer_options) && PB.encode(e, 3, x.optimizer_options)
    x.build_cost_model != zero(Int64) && PB.encode(e, 4, x.build_cost_model)
    x.build_cost_model_after != zero(Int64) && PB.encode(e, 9, x.build_cost_model_after)
    x.infer_shapes != false && PB.encode(e, 5, x.infer_shapes)
    x.place_pruned_graph != false && PB.encode(e, 6, x.place_pruned_graph)
    x.enable_bfloat16_sendrecv != false && PB.encode(e, 7, x.enable_bfloat16_sendrecv)
    x.timeline_step != zero(Int32) && PB.encode(e, 8, x.timeline_step)
    !isnothing(x.rewrite_options) && PB.encode(e, 10, x.rewrite_options)
    return position(e.io) - initpos
end
function PB._encoded_size(x::GraphOptions)
    encoded_size = 0
    x.enable_recv_scheduling != false && (encoded_size += PB._encoded_size(x.enable_recv_scheduling, 2))
    !isnothing(x.optimizer_options) && (encoded_size += PB._encoded_size(x.optimizer_options, 3))
    x.build_cost_model != zero(Int64) && (encoded_size += PB._encoded_size(x.build_cost_model, 4))
    x.build_cost_model_after != zero(Int64) && (encoded_size += PB._encoded_size(x.build_cost_model_after, 9))
    x.infer_shapes != false && (encoded_size += PB._encoded_size(x.infer_shapes, 5))
    x.place_pruned_graph != false && (encoded_size += PB._encoded_size(x.place_pruned_graph, 6))
    x.enable_bfloat16_sendrecv != false && (encoded_size += PB._encoded_size(x.enable_bfloat16_sendrecv, 7))
    x.timeline_step != zero(Int32) && (encoded_size += PB._encoded_size(x.timeline_step, 8))
    !isnothing(x.rewrite_options) && (encoded_size += PB._encoded_size(x.rewrite_options, 10))
    return encoded_size
end

struct RunOptions
    trace_level::var"RunOptions.TraceLevel".T
    timeout_in_ms::Int64
    inter_op_thread_pool::Int32
    output_partition_graphs::Bool
    debug_options::Union{Nothing,DebugOptions}
    report_tensor_allocations_upon_oom::Bool
    experimental::Union{Nothing,var"RunOptions.Experimental"}
end
PB.reserved_fields(::Type{RunOptions}) = (names = String[], numbers = Union{Int,UnitRange{Int}}[4])
PB.default_values(::Type{RunOptions}) = (;trace_level = var"RunOptions.TraceLevel".NO_TRACE, timeout_in_ms = zero(Int64), inter_op_thread_pool = zero(Int32), output_partition_graphs = false, debug_options = nothing, report_tensor_allocations_upon_oom = false, experimental = nothing)
PB.field_numbers(::Type{RunOptions}) = (;trace_level = 1, timeout_in_ms = 2, inter_op_thread_pool = 3, output_partition_graphs = 5, debug_options = 6, report_tensor_allocations_upon_oom = 7, experimental = 8)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:RunOptions})
    trace_level = var"RunOptions.TraceLevel".NO_TRACE
    timeout_in_ms = zero(Int64)
    inter_op_thread_pool = zero(Int32)
    output_partition_graphs = false
    debug_options = Ref{Union{Nothing,DebugOptions}}(nothing)
    report_tensor_allocations_upon_oom = false
    experimental = Ref{Union{Nothing,var"RunOptions.Experimental"}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            trace_level = PB.decode(d, var"RunOptions.TraceLevel".T)
        elseif field_number == 2
            timeout_in_ms = PB.decode(d, Int64)
        elseif field_number == 3
            inter_op_thread_pool = PB.decode(d, Int32)
        elseif field_number == 5
            output_partition_graphs = PB.decode(d, Bool)
        elseif field_number == 6
            PB.decode!(d, debug_options)
        elseif field_number == 7
            report_tensor_allocations_upon_oom = PB.decode(d, Bool)
        elseif field_number == 8
            PB.decode!(d, experimental)
        else
            PB.skip(d, wire_type)
        end
    end
    return RunOptions(trace_level, timeout_in_ms, inter_op_thread_pool, output_partition_graphs, debug_options[], report_tensor_allocations_upon_oom, experimental[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::RunOptions)
    initpos = position(e.io)
    x.trace_level != var"RunOptions.TraceLevel".NO_TRACE && PB.encode(e, 1, x.trace_level)
    x.timeout_in_ms != zero(Int64) && PB.encode(e, 2, x.timeout_in_ms)
    x.inter_op_thread_pool != zero(Int32) && PB.encode(e, 3, x.inter_op_thread_pool)
    x.output_partition_graphs != false && PB.encode(e, 5, x.output_partition_graphs)
    !isnothing(x.debug_options) && PB.encode(e, 6, x.debug_options)
    x.report_tensor_allocations_upon_oom != false && PB.encode(e, 7, x.report_tensor_allocations_upon_oom)
    !isnothing(x.experimental) && PB.encode(e, 8, x.experimental)
    return position(e.io) - initpos
end
function PB._encoded_size(x::RunOptions)
    encoded_size = 0
    x.trace_level != var"RunOptions.TraceLevel".NO_TRACE && (encoded_size += PB._encoded_size(x.trace_level, 1))
    x.timeout_in_ms != zero(Int64) && (encoded_size += PB._encoded_size(x.timeout_in_ms, 2))
    x.inter_op_thread_pool != zero(Int32) && (encoded_size += PB._encoded_size(x.inter_op_thread_pool, 3))
    x.output_partition_graphs != false && (encoded_size += PB._encoded_size(x.output_partition_graphs, 5))
    !isnothing(x.debug_options) && (encoded_size += PB._encoded_size(x.debug_options, 6))
    x.report_tensor_allocations_upon_oom != false && (encoded_size += PB._encoded_size(x.report_tensor_allocations_upon_oom, 7))
    !isnothing(x.experimental) && (encoded_size += PB._encoded_size(x.experimental, 8))
    return encoded_size
end

struct ConfigProto
    device_count::Dict{String,Int32}
    intra_op_parallelism_threads::Int32
    inter_op_parallelism_threads::Int32
    use_per_session_threads::Bool
    session_inter_op_thread_pool::Vector{ThreadPoolOptionProto}
    placement_period::Int32
    device_filters::Vector{String}
    gpu_options::Union{Nothing,GPUOptions}
    allow_soft_placement::Bool
    log_device_placement::Bool
    graph_options::Union{Nothing,GraphOptions}
    operation_timeout_in_ms::Int64
    rpc_options::Union{Nothing,RPCOptions}
    cluster_def::Union{Nothing,ClusterDef}
    isolate_session_state::Bool
    share_cluster_devices_in_session::Bool
    experimental::Union{Nothing,var"ConfigProto.Experimental"}
end
PB.default_values(::Type{ConfigProto}) = (;device_count = Dict{String,Int32}(), intra_op_parallelism_threads = zero(Int32), inter_op_parallelism_threads = zero(Int32), use_per_session_threads = false, session_inter_op_thread_pool = Vector{ThreadPoolOptionProto}(), placement_period = zero(Int32), device_filters = Vector{String}(), gpu_options = nothing, allow_soft_placement = false, log_device_placement = false, graph_options = nothing, operation_timeout_in_ms = zero(Int64), rpc_options = nothing, cluster_def = nothing, isolate_session_state = false, share_cluster_devices_in_session = false, experimental = nothing)
PB.field_numbers(::Type{ConfigProto}) = (;device_count = 1, intra_op_parallelism_threads = 2, inter_op_parallelism_threads = 5, use_per_session_threads = 9, session_inter_op_thread_pool = 12, placement_period = 3, device_filters = 4, gpu_options = 6, allow_soft_placement = 7, log_device_placement = 8, graph_options = 10, operation_timeout_in_ms = 11, rpc_options = 13, cluster_def = 14, isolate_session_state = 15, share_cluster_devices_in_session = 17, experimental = 16)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:ConfigProto})
    device_count = Dict{String,Int32}()
    intra_op_parallelism_threads = zero(Int32)
    inter_op_parallelism_threads = zero(Int32)
    use_per_session_threads = false
    session_inter_op_thread_pool = PB.BufferedVector{ThreadPoolOptionProto}()
    placement_period = zero(Int32)
    device_filters = PB.BufferedVector{String}()
    gpu_options = Ref{Union{Nothing,GPUOptions}}(nothing)
    allow_soft_placement = false
    log_device_placement = false
    graph_options = Ref{Union{Nothing,GraphOptions}}(nothing)
    operation_timeout_in_ms = zero(Int64)
    rpc_options = Ref{Union{Nothing,RPCOptions}}(nothing)
    cluster_def = Ref{Union{Nothing,ClusterDef}}(nothing)
    isolate_session_state = false
    share_cluster_devices_in_session = false
    experimental = Ref{Union{Nothing,var"ConfigProto.Experimental"}}(nothing)
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, device_count)
        elseif field_number == 2
            intra_op_parallelism_threads = PB.decode(d, Int32)
        elseif field_number == 5
            inter_op_parallelism_threads = PB.decode(d, Int32)
        elseif field_number == 9
            use_per_session_threads = PB.decode(d, Bool)
        elseif field_number == 12
            PB.decode!(d, session_inter_op_thread_pool)
        elseif field_number == 3
            placement_period = PB.decode(d, Int32)
        elseif field_number == 4
            PB.decode!(d, device_filters)
        elseif field_number == 6
            PB.decode!(d, gpu_options)
        elseif field_number == 7
            allow_soft_placement = PB.decode(d, Bool)
        elseif field_number == 8
            log_device_placement = PB.decode(d, Bool)
        elseif field_number == 10
            PB.decode!(d, graph_options)
        elseif field_number == 11
            operation_timeout_in_ms = PB.decode(d, Int64)
        elseif field_number == 13
            PB.decode!(d, rpc_options)
        elseif field_number == 14
            PB.decode!(d, cluster_def)
        elseif field_number == 15
            isolate_session_state = PB.decode(d, Bool)
        elseif field_number == 17
            share_cluster_devices_in_session = PB.decode(d, Bool)
        elseif field_number == 16
            PB.decode!(d, experimental)
        else
            PB.skip(d, wire_type)
        end
    end
    return ConfigProto(device_count, intra_op_parallelism_threads, inter_op_parallelism_threads, use_per_session_threads, session_inter_op_thread_pool[], placement_period, device_filters[], gpu_options[], allow_soft_placement, log_device_placement, graph_options[], operation_timeout_in_ms, rpc_options[], cluster_def[], isolate_session_state, share_cluster_devices_in_session, experimental[])
end

function PB.encode(e::PB.AbstractProtoEncoder, x::ConfigProto)
    initpos = position(e.io)
    !isempty(x.device_count) && PB.encode(e, 1, x.device_count)
    x.intra_op_parallelism_threads != zero(Int32) && PB.encode(e, 2, x.intra_op_parallelism_threads)
    x.inter_op_parallelism_threads != zero(Int32) && PB.encode(e, 5, x.inter_op_parallelism_threads)
    x.use_per_session_threads != false && PB.encode(e, 9, x.use_per_session_threads)
    !isempty(x.session_inter_op_thread_pool) && PB.encode(e, 12, x.session_inter_op_thread_pool)
    x.placement_period != zero(Int32) && PB.encode(e, 3, x.placement_period)
    !isempty(x.device_filters) && PB.encode(e, 4, x.device_filters)
    !isnothing(x.gpu_options) && PB.encode(e, 6, x.gpu_options)
    x.allow_soft_placement != false && PB.encode(e, 7, x.allow_soft_placement)
    x.log_device_placement != false && PB.encode(e, 8, x.log_device_placement)
    !isnothing(x.graph_options) && PB.encode(e, 10, x.graph_options)
    x.operation_timeout_in_ms != zero(Int64) && PB.encode(e, 11, x.operation_timeout_in_ms)
    !isnothing(x.rpc_options) && PB.encode(e, 13, x.rpc_options)
    !isnothing(x.cluster_def) && PB.encode(e, 14, x.cluster_def)
    x.isolate_session_state != false && PB.encode(e, 15, x.isolate_session_state)
    x.share_cluster_devices_in_session != false && PB.encode(e, 17, x.share_cluster_devices_in_session)
    !isnothing(x.experimental) && PB.encode(e, 16, x.experimental)
    return position(e.io) - initpos
end
function PB._encoded_size(x::ConfigProto)
    encoded_size = 0
    !isempty(x.device_count) && (encoded_size += PB._encoded_size(x.device_count, 1))
    x.intra_op_parallelism_threads != zero(Int32) && (encoded_size += PB._encoded_size(x.intra_op_parallelism_threads, 2))
    x.inter_op_parallelism_threads != zero(Int32) && (encoded_size += PB._encoded_size(x.inter_op_parallelism_threads, 5))
    x.use_per_session_threads != false && (encoded_size += PB._encoded_size(x.use_per_session_threads, 9))
    !isempty(x.session_inter_op_thread_pool) && (encoded_size += PB._encoded_size(x.session_inter_op_thread_pool, 12))
    x.placement_period != zero(Int32) && (encoded_size += PB._encoded_size(x.placement_period, 3))
    !isempty(x.device_filters) && (encoded_size += PB._encoded_size(x.device_filters, 4))
    !isnothing(x.gpu_options) && (encoded_size += PB._encoded_size(x.gpu_options, 6))
    x.allow_soft_placement != false && (encoded_size += PB._encoded_size(x.allow_soft_placement, 7))
    x.log_device_placement != false && (encoded_size += PB._encoded_size(x.log_device_placement, 8))
    !isnothing(x.graph_options) && (encoded_size += PB._encoded_size(x.graph_options, 10))
    x.operation_timeout_in_ms != zero(Int64) && (encoded_size += PB._encoded_size(x.operation_timeout_in_ms, 11))
    !isnothing(x.rpc_options) && (encoded_size += PB._encoded_size(x.rpc_options, 13))
    !isnothing(x.cluster_def) && (encoded_size += PB._encoded_size(x.cluster_def, 14))
    x.isolate_session_state != false && (encoded_size += PB._encoded_size(x.isolate_session_state, 15))
    x.share_cluster_devices_in_session != false && (encoded_size += PB._encoded_size(x.share_cluster_devices_in_session, 17))
    !isnothing(x.experimental) && (encoded_size += PB._encoded_size(x.experimental, 16))
    return encoded_size
end

struct CallableOptions
    feed::Vector{String}
    fetch::Vector{String}
    target::Vector{String}
    run_options::Union{Nothing,RunOptions}
    tensor_connection::Vector{TensorConnection}
    feed_devices::Dict{String,String}
    fetch_devices::Dict{String,String}
    fetch_skip_sync::Bool
end
PB.default_values(::Type{CallableOptions}) = (;feed = Vector{String}(), fetch = Vector{String}(), target = Vector{String}(), run_options = nothing, tensor_connection = Vector{TensorConnection}(), feed_devices = Dict{String,String}(), fetch_devices = Dict{String,String}(), fetch_skip_sync = false)
PB.field_numbers(::Type{CallableOptions}) = (;feed = 1, fetch = 2, target = 3, run_options = 4, tensor_connection = 5, feed_devices = 6, fetch_devices = 7, fetch_skip_sync = 8)

function PB.decode(d::PB.AbstractProtoDecoder, ::Type{<:CallableOptions})
    feed = PB.BufferedVector{String}()
    fetch = PB.BufferedVector{String}()
    target = PB.BufferedVector{String}()
    run_options = Ref{Union{Nothing,RunOptions}}(nothing)
    tensor_connection = PB.BufferedVector{TensorConnection}()
    feed_devices = Dict{String,String}()
    fetch_devices = Dict{String,String}()
    fetch_skip_sync = false
    while !PB.message_done(d)
        field_number, wire_type = PB.decode_tag(d)
        if field_number == 1
            PB.decode!(d, feed)
        elseif field_number == 2
            PB.decode!(d, fetch)
        elseif field_number == 3
            PB.decode!(d, target)
        elseif field_number == 4
            PB.decode!(d, run_options)
        elseif field_number == 5
            PB.decode!(d, tensor_connection)
        elseif field_number == 6
            PB.decode!(d, feed_devices)
        elseif field_number == 7
            PB.decode!(d, fetch_devices)
        elseif field_number == 8
            fetch_skip_sync = PB.decode(d, Bool)
        else
            PB.skip(d, wire_type)
        end
    end
    return CallableOptions(feed[], fetch[], target[], run_options[], tensor_connection[], feed_devices, fetch_devices, fetch_skip_sync)
end

function PB.encode(e::PB.AbstractProtoEncoder, x::CallableOptions)
    initpos = position(e.io)
    !isempty(x.feed) && PB.encode(e, 1, x.feed)
    !isempty(x.fetch) && PB.encode(e, 2, x.fetch)
    !isempty(x.target) && PB.encode(e, 3, x.target)
    !isnothing(x.run_options) && PB.encode(e, 4, x.run_options)
    !isempty(x.tensor_connection) && PB.encode(e, 5, x.tensor_connection)
    !isempty(x.feed_devices) && PB.encode(e, 6, x.feed_devices)
    !isempty(x.fetch_devices) && PB.encode(e, 7, x.fetch_devices)
    x.fetch_skip_sync != false && PB.encode(e, 8, x.fetch_skip_sync)
    return position(e.io) - initpos
end
function PB._encoded_size(x::CallableOptions)
    encoded_size = 0
    !isempty(x.feed) && (encoded_size += PB._encoded_size(x.feed, 1))
    !isempty(x.fetch) && (encoded_size += PB._encoded_size(x.fetch, 2))
    !isempty(x.target) && (encoded_size += PB._encoded_size(x.target, 3))
    !isnothing(x.run_options) && (encoded_size += PB._encoded_size(x.run_options, 4))
    !isempty(x.tensor_connection) && (encoded_size += PB._encoded_size(x.tensor_connection, 5))
    !isempty(x.feed_devices) && (encoded_size += PB._encoded_size(x.feed_devices, 6))
    !isempty(x.fetch_devices) && (encoded_size += PB._encoded_size(x.fetch_devices, 7))
    x.fetch_skip_sync != false && (encoded_size += PB._encoded_size(x.fetch_skip_sync, 8))
    return encoded_size
end